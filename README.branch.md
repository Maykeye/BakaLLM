# BakaStacking: Who need to train everything at once? 

Based on https://arxiv.org/abs/2011.13635 and similar

Idea is to train only some layer at time


Training:

1) Naive

Mew layer is simply added. No copying done.

After 10 steps: VAL: 3.85
